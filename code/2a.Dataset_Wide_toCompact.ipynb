{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import distutils\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Input Size:  (1101, 74)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = pd.read_csv(\"../data/processed/gw_stage2.CSV\",\n",
    "                    parse_dates=['Datetime'],\n",
    "                    index_col=['Datetime'])\n",
    "print('Initial Input Size: ',X.shape)\n",
    "y = pd.read_csv(\"../data/processed/spring.CSV\",\n",
    "                    parse_dates=['datetime'],\n",
    "                    index_col=['datetime'])\n",
    "\n",
    "X.head(10)\n",
    "\n",
    "key_value = np.loadtxt(\"../data/processed/NameKey2.CSV\", dtype= \"str\", delimiter=\",\", skiprows=1)\n",
    "stationNames = { k:v for k,v in key_value }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prep Dict Keys as an int and a string\n",
    "keyint=list(range(0,74))\n",
    "#print(keyint)\n",
    "key_str=[str(x) for x in keyint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_Name</th>\n",
       "      <th>key</th>\n",
       "      <th>ts_type</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>frequency</th>\n",
       "      <th>h_ts</th>\n",
       "      <th>series_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Station_Name, key, ts_type, start_timestamp, frequency, h_ts, series_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set up new Df\n",
    "new_df=pd.DataFrame(columns=['Station_Name', \"key\", 'ts_type',\"start_timestamp\", 'frequency', 'h_ts', 'series_length'])\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_dict=[]\n",
    "for i in range(74):\n",
    "    if i<=29:\n",
    "        station_type='GW'\n",
    "    else:\n",
    "        station_type='SW'\n",
    "    a=stationNames[key_str[i]]\n",
    "    #print(a)\n",
    "    test=X.loc[:,a]\n",
    "    z=test.tolist()\n",
    "    lst_dict.append({'Station_Name': test.name, 'key':key_str[i], 'ts_type': station_type, \n",
    "                       'start_timestamp':\"2017-01-27\", 'frequency':\"1D\", 'h_ts':z, \n",
    "                       'series_length': test.size})\n",
    "    df2=new_df.append(lst_dict)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_Name</th>\n",
       "      <th>key</th>\n",
       "      <th>ts_type</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>frequency</th>\n",
       "      <th>h_ts</th>\n",
       "      <th>series_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USGS-LESTER LEWIS/S788</td>\n",
       "      <td>0</td>\n",
       "      <td>GW</td>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>1D</td>\n",
       "      <td>[6.340833333, 6.220729167, 6.1534375, 6.046041...</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NWFWMD-BIKE TRAIL / NITRATE POT. MAP/S795</td>\n",
       "      <td>1</td>\n",
       "      <td>GW</td>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>1D</td>\n",
       "      <td>[15.02541667, 15.08229167, 15.1109375, 15.0711...</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NWFWMD-BRADFORD BROOK DEEP/S793</td>\n",
       "      <td>2</td>\n",
       "      <td>GW</td>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>1D</td>\n",
       "      <td>[20.72239583, 20.79333333, 20.8790625, 20.8895...</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NWFWMD-BRADFORD BROOK SHALLOW</td>\n",
       "      <td>3</td>\n",
       "      <td>GW</td>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>1D</td>\n",
       "      <td>[38.61302083, 38.61760417, 38.6271875, 38.5586...</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOM BROWN TEST/S791</td>\n",
       "      <td>4</td>\n",
       "      <td>GW</td>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>1D</td>\n",
       "      <td>[25.915625, 26.0184375, 26.03791667, 25.949375...</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>LAKE KILLARNY AT MCLAUGHLIN DRIVE</td>\n",
       "      <td>70</td>\n",
       "      <td>SW</td>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>1D</td>\n",
       "      <td>[73.27979167, 73.21723959, 73.16114583, 73.118...</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>LAKE KANTURK AT CLIFDEN DR</td>\n",
       "      <td>71</td>\n",
       "      <td>SW</td>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>1D</td>\n",
       "      <td>[73.31546875, 73.25291667, 73.19697917, 73.152...</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>INDIAN SPRING RUN AT SR61</td>\n",
       "      <td>72</td>\n",
       "      <td>SW</td>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>1D</td>\n",
       "      <td>[5.243125, 5.170104167, 5.105208333, 5.0539583...</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>ST. MARKS RIVER - UPPER DISCHARGE BEFORE SWALLET</td>\n",
       "      <td>73</td>\n",
       "      <td>SW</td>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>1D</td>\n",
       "      <td>[9.488892223, 9.488892223, 9.488892223, 9.4888...</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Wakulla_Springs_USGS</td>\n",
       "      <td>74</td>\n",
       "      <td>spring</td>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>1D</td>\n",
       "      <td>[5.470909091, 5.418020833, 5.3453125, 5.237916...</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Station_Name key ts_type  \\\n",
       "0                             USGS-LESTER LEWIS/S788   0      GW   \n",
       "1          NWFWMD-BIKE TRAIL / NITRATE POT. MAP/S795   1      GW   \n",
       "2                    NWFWMD-BRADFORD BROOK DEEP/S793   2      GW   \n",
       "3                      NWFWMD-BRADFORD BROOK SHALLOW   3      GW   \n",
       "4                                TOM BROWN TEST/S791   4      GW   \n",
       "..                                               ...  ..     ...   \n",
       "70                 LAKE KILLARNY AT MCLAUGHLIN DRIVE  70      SW   \n",
       "71                        LAKE KANTURK AT CLIFDEN DR  71      SW   \n",
       "72                         INDIAN SPRING RUN AT SR61  72      SW   \n",
       "73  ST. MARKS RIVER - UPPER DISCHARGE BEFORE SWALLET  73      SW   \n",
       "74                              Wakulla_Springs_USGS  74  spring   \n",
       "\n",
       "   start_timestamp frequency  \\\n",
       "0       2017-01-27        1D   \n",
       "1       2017-01-27        1D   \n",
       "2       2017-01-27        1D   \n",
       "3       2017-01-27        1D   \n",
       "4       2017-01-27        1D   \n",
       "..             ...       ...   \n",
       "70      2017-01-27        1D   \n",
       "71      2017-01-27        1D   \n",
       "72      2017-01-27        1D   \n",
       "73      2017-01-27        1D   \n",
       "74      2017-01-27        1D   \n",
       "\n",
       "                                                 h_ts series_length  \n",
       "0   [6.340833333, 6.220729167, 6.1534375, 6.046041...          1101  \n",
       "1   [15.02541667, 15.08229167, 15.1109375, 15.0711...          1101  \n",
       "2   [20.72239583, 20.79333333, 20.8790625, 20.8895...          1101  \n",
       "3   [38.61302083, 38.61760417, 38.6271875, 38.5586...          1101  \n",
       "4   [25.915625, 26.0184375, 26.03791667, 25.949375...          1101  \n",
       "..                                                ...           ...  \n",
       "70  [73.27979167, 73.21723959, 73.16114583, 73.118...          1101  \n",
       "71  [73.31546875, 73.25291667, 73.19697917, 73.152...          1101  \n",
       "72  [5.243125, 5.170104167, 5.105208333, 5.0539583...          1101  \n",
       "73  [9.488892223, 9.488892223, 9.488892223, 9.4888...          1101  \n",
       "74  [5.470909091, 5.418020833, 5.3453125, 5.237916...          1101  \n",
       "\n",
       "[75 rows x 7 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=y['Gage_Height'].tolist()\n",
    "spring_dict=[{'Station_Name': \"Wakulla_Springs_USGS\", 'key':74, 'ts_type': \"spring\", \n",
    "                       'start_timestamp':\"2017-01-27\", 'frequency':\"1D\", 'h_ts': z, \n",
    "                       'series_length': len(z)}]\n",
    "df2=df2.append(spring_dict, ignore_index=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_compact_to_ts(\n",
    "    df: pd.DataFrame,\n",
    "    filename: str,\n",
    "    static_columns: list,\n",
    "    time_varying_columns: list,\n",
    "    sep: str = \";\",\n",
    "    encoding: str = \"utf-8\",\n",
    "    date_format: str = \"%Y-%m-%d %H-%M-%S\",\n",
    "    chunk_size: int = 50,\n",
    "):\n",
    "    \"\"\"Writes a dataframe in the compact form to disk\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe in compact form\n",
    "        filename (str): Filename to which the dataframe should be written to\n",
    "        static_columns (list): List of column names of static features\n",
    "        time_varying_columns (list): List of column names of time varying columns\n",
    "        sep (str, optional): Separator with which the arrays are stored in the text file. Defaults to \";\".\n",
    "        encoding (str, optional): encoding of the text file. Defaults to \"utf-8\".\n",
    "        date_format (str, optional): Format in which datetime shud be written out in text file. Defaults to \"%Y-%m-%d %H-%M-%S\".\n",
    "        chunk_size (int, optional): Chunk size while writing files to disk. Defaults to 50.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if sep == \":\":\n",
    "        warnings.warn(\n",
    "            \"Using `:` as separator will not work well if `:` is present in the string representation of date time.\"\n",
    "        )\n",
    "    with open(filename, \"w\", encoding=encoding) as f:\n",
    "        for c, dtype in df.dtypes.items():\n",
    "            if c in static_columns:\n",
    "                typ = \"static\"\n",
    "            elif c in time_varying_columns:\n",
    "                typ = \"time_varying\"\n",
    "            f.write(f\"@column {c} {dtype.name} {typ}\")\n",
    "            f.write(\"\\n\")\n",
    "        f.write(f\"@data\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        def write_ts(x):\n",
    "            l = \"\"\n",
    "            for c in x.index:\n",
    "                if isinstance(x[c], np.ndarray):\n",
    "                    l += \"|\".join(x[c].astype(str))\n",
    "                    l += sep\n",
    "                elif isinstance(x[c], pd.Timestamp):\n",
    "                    l += x[c].strftime(date_format)\n",
    "                    l += sep\n",
    "                else:\n",
    "                    l += str(x[c])\n",
    "                    l += sep\n",
    "            l += \"\\n\"\n",
    "            return l\n",
    "\n",
    "        [\n",
    "            f.writelines([write_ts(x.loc[i]) for i in tqdm(x.index)])\n",
    "            for x in tqdm(\n",
    "                np.split(df, np.arange(chunk_size, len(df), chunk_size)),\n",
    "                desc=\"Writing in Chunks...\",\n",
    "            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing in Chunks...:   0%|                                                                      | 0/2 [00:00<?, ?it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 847.72it/s]\u001b[A\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 926.22it/s]\u001b[A\n",
      "Writing in Chunks...: 100%|██████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 20.41it/s]\n"
     ]
    }
   ],
   "source": [
    "write_compact_to_ts(df2,\n",
    "    static_columns = ['Station_Name', 'key', 'ts_type','series_length', 'frequency', 'start_timestamp'], \n",
    "    time_varying_columns = ['h_ts'],\n",
    "    filename=f\"../data/processed/GW_SW_Daily.ts\",\n",
    "    sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compact_to_expanded(\n",
    "    df, timeseries_col, static_cols, time_varying_cols, ts_identifier):\n",
    "    def preprocess_expanded(x):\n",
    "        ### Fill missing dates with NaN ###\n",
    "        # Create a date range from  start\n",
    "        dr = pd.date_range(\n",
    "            start=x[\"start_timestamp\"],\n",
    "            periods=len(x[\"h_ts\"]),\n",
    "            freq=x[\"frequency\"],\n",
    "        )\n",
    "        df_columns = defaultdict(list)\n",
    "        df_columns[\"timestamp\"] = dr\n",
    "        for col in [ts_identifier, timeseries_col] + static_cols + time_varying_cols:\n",
    "            df_columns[col] = x[col]\n",
    "        return pd.DataFrame(df_columns)\n",
    "        \n",
    "\n",
    "    all_series = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        all_series.append(preprocess_expanded(df.iloc[i]))\n",
    "    df = pd.concat(all_series)\n",
    "    del all_series\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 765.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Station_Name</th>\n",
       "      <th>h_ts</th>\n",
       "      <th>key</th>\n",
       "      <th>ts_type</th>\n",
       "      <th>series_length</th>\n",
       "      <th>frequency</th>\n",
       "      <th>start_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>USGS-LESTER LEWIS/S788</td>\n",
       "      <td>6.340833</td>\n",
       "      <td>0</td>\n",
       "      <td>GW</td>\n",
       "      <td>1101</td>\n",
       "      <td>1D</td>\n",
       "      <td>2017-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>USGS-LESTER LEWIS/S788</td>\n",
       "      <td>6.220729</td>\n",
       "      <td>0</td>\n",
       "      <td>GW</td>\n",
       "      <td>1101</td>\n",
       "      <td>1D</td>\n",
       "      <td>2017-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>USGS-LESTER LEWIS/S788</td>\n",
       "      <td>6.153437</td>\n",
       "      <td>0</td>\n",
       "      <td>GW</td>\n",
       "      <td>1101</td>\n",
       "      <td>1D</td>\n",
       "      <td>2017-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>USGS-LESTER LEWIS/S788</td>\n",
       "      <td>6.046042</td>\n",
       "      <td>0</td>\n",
       "      <td>GW</td>\n",
       "      <td>1101</td>\n",
       "      <td>1D</td>\n",
       "      <td>2017-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>USGS-LESTER LEWIS/S788</td>\n",
       "      <td>5.991562</td>\n",
       "      <td>0</td>\n",
       "      <td>GW</td>\n",
       "      <td>1101</td>\n",
       "      <td>1D</td>\n",
       "      <td>2017-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>Wakulla_Springs_USGS</td>\n",
       "      <td>4.814896</td>\n",
       "      <td>74</td>\n",
       "      <td>spring</td>\n",
       "      <td>1101</td>\n",
       "      <td>1D</td>\n",
       "      <td>2017-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>Wakulla_Springs_USGS</td>\n",
       "      <td>4.811146</td>\n",
       "      <td>74</td>\n",
       "      <td>spring</td>\n",
       "      <td>1101</td>\n",
       "      <td>1D</td>\n",
       "      <td>2017-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>Wakulla_Springs_USGS</td>\n",
       "      <td>4.807292</td>\n",
       "      <td>74</td>\n",
       "      <td>spring</td>\n",
       "      <td>1101</td>\n",
       "      <td>1D</td>\n",
       "      <td>2017-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>Wakulla_Springs_USGS</td>\n",
       "      <td>4.777188</td>\n",
       "      <td>74</td>\n",
       "      <td>spring</td>\n",
       "      <td>1101</td>\n",
       "      <td>1D</td>\n",
       "      <td>2017-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Wakulla_Springs_USGS</td>\n",
       "      <td>4.794500</td>\n",
       "      <td>74</td>\n",
       "      <td>spring</td>\n",
       "      <td>1101</td>\n",
       "      <td>1D</td>\n",
       "      <td>2017-01-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82575 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp            Station_Name      h_ts key ts_type  series_length  \\\n",
       "0    2017-01-27  USGS-LESTER LEWIS/S788  6.340833   0      GW           1101   \n",
       "1    2017-01-28  USGS-LESTER LEWIS/S788  6.220729   0      GW           1101   \n",
       "2    2017-01-29  USGS-LESTER LEWIS/S788  6.153437   0      GW           1101   \n",
       "3    2017-01-30  USGS-LESTER LEWIS/S788  6.046042   0      GW           1101   \n",
       "4    2017-01-31  USGS-LESTER LEWIS/S788  5.991562   0      GW           1101   \n",
       "...         ...                     ...       ...  ..     ...            ...   \n",
       "1096 2020-01-28    Wakulla_Springs_USGS  4.814896  74  spring           1101   \n",
       "1097 2020-01-29    Wakulla_Springs_USGS  4.811146  74  spring           1101   \n",
       "1098 2020-01-30    Wakulla_Springs_USGS  4.807292  74  spring           1101   \n",
       "1099 2020-01-31    Wakulla_Springs_USGS  4.777188  74  spring           1101   \n",
       "1100 2020-02-01    Wakulla_Springs_USGS  4.794500  74  spring           1101   \n",
       "\n",
       "     frequency start_timestamp  \n",
       "0           1D      2017-01-27  \n",
       "1           1D      2017-01-27  \n",
       "2           1D      2017-01-27  \n",
       "3           1D      2017-01-27  \n",
       "4           1D      2017-01-27  \n",
       "...        ...             ...  \n",
       "1096        1D      2017-01-27  \n",
       "1097        1D      2017-01-27  \n",
       "1098        1D      2017-01-27  \n",
       "1099        1D      2017-01-27  \n",
       "1100        1D      2017-01-27  \n",
       "\n",
       "[82575 rows x 8 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df=compact_to_expanded(\n",
    "    df2, timeseries_col='h_ts',\n",
    "    static_cols=['key', 'ts_type','series_length', 'frequency', 'start_timestamp'],\n",
    "    time_varying_cols=[],\n",
    "    ts_identifier='Station_Name')\n",
    "\n",
    "exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-d57cae7e0455>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time_idx'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#diff = data.iloc[1]['time_idx'] - data.iloc[0]['time_idx']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#data[\"_min_time_idx\"] = data.groupby(\"LCLid\", observed=True)['time_idx'].transform(\"min\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#data['time_idx'] = ((data['time_idx']-data['_min_time_idx'])/diff).astype(int)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'timestamp'"
     ]
    }
   ],
   "source": [
    "idx = pd.date_range(\"2017-01-27\", periods=1101, freq=\"D\")\n",
    "ts = pd.Series(range(len(idx)), index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_footprint(df):\n",
    "    dtypes = df.dtypes\n",
    "    object_cols = dtypes[dtypes == \"object\"].index.tolist()\n",
    "    float_cols = dtypes[dtypes == \"float64\"].index.tolist()\n",
    "    int_cols = dtypes[dtypes == \"int64\"].index.tolist()\n",
    "    df[int_cols] = df[int_cols].astype(\"int32\")\n",
    "    df[object_cols] = df[object_cols].astype(\"category\")\n",
    "    df[float_cols] = df[float_cols].astype(\"float32\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 82575 entries, 0 to 1100\n",
      "Columns: 7 entries, timestamp to frequency\n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(4)\n",
      "memory usage: 23.1 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 82575 entries, 0 to 1100\n",
      "Columns: 7 entries, timestamp to frequency\n",
      "dtypes: category(4), datetime64[ns](1), float32(1), int32(1)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "exp_df.info(memory_usage=\"deep\", verbose=False)\n",
    "exp_df = reduce_memory_footprint(exp_df)\n",
    "\n",
    "exp_df.info(memory_usage=\"deep\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train/Test Split of 70% Train 20% Val and 20% Test. Dates for these are calcualted outside of\n",
    "\n",
    "test_mask =(exp_df['timestamp'] >= '2019-03-08')\n",
    "\n",
    "train = exp_df[~(test_mask)]\n",
    "\n",
    "test = exp_df[test_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"../data/processed/daily_train.CSV\")\n",
    "#val.to_csv(\"../data/processed/daily_val.CSV\")\n",
    "test.to_csv(\"../data/processed/daily_test.CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
